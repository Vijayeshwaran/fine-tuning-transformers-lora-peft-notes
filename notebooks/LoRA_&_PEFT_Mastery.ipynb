{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "üß≠ Our Roadmap to Mastery\n",
        "\n",
        "1. What is Fine-Tuning and Why It's Expensive\n",
        "\n",
        "2. PEFT - Parameter-Efficient Fine-Tuning\n",
        "\n",
        "3. LoRA - Low-Rank Adaptation\n",
        "\n",
        "  - Deep Dive into LoRA\n",
        "\n",
        "    - Linear Layers & Matrix Decomposition\n",
        "\n",
        "    - The core idea of LoRA\n",
        "\n",
        "    - Implementation walkthrough\n",
        "\n",
        "    - Pros & Limitations\n",
        "\n",
        "5. Comparison: LoRA vs Other PEFT methods\n",
        "\n",
        "6. Advanced: QLoRA, AdaLoRA, LoRA with Transformers\n",
        "\n",
        "7. Hands-On: Fine-tuning a HuggingFace model using LoRA\n",
        "___"
      ],
      "metadata": {
        "id": "cW2AsBgDuDhf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîπ 1. What is Fine-Tuning and Why It's Expensive?"
      ],
      "metadata": {
        "id": "4zvRDb8CxE3r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† What is Fine-Tuning?\n",
        "\n",
        "Fine-tuning is a process where you take a pre-trained model (like BERT, GPT, or ViT) and adjust its parameters slightly so that it performs well on a specific downstream task ‚Äî such as classification, QA, or summarization.\n",
        "\n",
        "- Pre-trained models are trained on large, generic datasets (e.g., Wikipedia, Common Crawl).\n",
        "\n",
        "- Fine-tuning adapts the model to a smaller, task-specific dataset (e.g., product classification, sentiment analysis).\n",
        "\n",
        "üß™ Think of it like customizing a car ‚Äî the base car is great, but you add features for your specific needs (GPS, baby seat, etc.)."
      ],
      "metadata": {
        "id": "puArLKPmu2Pw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîç Example:\n",
        "\n",
        "- Pretrained BERT ‚Üí Fine-tune on your product description classification task.\n",
        "\n",
        "- Pretrained ViT ‚Üí Fine-tune on your fashion image categorization."
      ],
      "metadata": {
        "id": "ZTocKMKIvYnH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚öôÔ∏è What Happens Under the Hood?\n",
        "\n",
        "All model parameters (sometimes hundreds of millions) are updated through backpropagation using your task-specific data."
      ],
      "metadata": {
        "id": "UqmU8gIVvyFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ü§î Real-World Problem\n",
        "\n",
        "You want to adapt an LLM like GPT or BERT to 50 different tasks, but:\n",
        "\n",
        "- You don‚Äôt have enough GPU resources.\n",
        "\n",
        "- You don‚Äôt want to retrain the whole model each time.\n",
        "\n",
        "- You want to reuse the base model and store only small \"adapters\" for each task."
      ],
      "metadata": {
        "id": "O3PxuaO1wYiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîÑ This is where PEFT comes in!\n",
        "\n",
        "Rather than updating all parameters, PEFT updates only a small number of parameters (often <1%) and freezes the rest.\n",
        "___"
      ],
      "metadata": {
        "id": "PXMWF6v2wvaR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîπ 2. PEFT ‚Äì Parameter-Efficient Fine-Tuning"
      ],
      "metadata": {
        "id": "rxvA4j1wxJcQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† What is PEFT?\n",
        "\n",
        "PEFT (Parameter-Efficient Fine-Tuning) is a set of techniques that adapts large pre-trained models for new tasks by only training a small subset of parameters.\n",
        "\n",
        "üîß Instead of fine-tuning the entire engine, you‚Äôre just tweaking a few components to fit your task."
      ],
      "metadata": {
        "id": "3gSQsOP8xrgH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üöÄ Why PEFT?\n",
        "\n",
        "    Traditional                             Fine-Tuning PEFT\n",
        "    ------------------------------------------------------------------\n",
        "    Updates all parameters\t            Updates only a small subset\n",
        "    High memory + compute cost\t        Low memory + fast training\n",
        "    Large model copies per task\t       Small ‚Äúadapter‚Äù per task\n",
        "    Difficult multi-task scaling\t      Easy multi-task deployment"
      ],
      "metadata": {
        "id": "zHG594BwxwUq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üõ†Ô∏è Core Idea Behind PEFT\n",
        "\n",
        "- Freeze the original model weights\n",
        "\n",
        "- Add/train only a few lightweight modules\n",
        "\n",
        "- This allows reuse of the base model, and you just plug in the task-specific pieces."
      ],
      "metadata": {
        "id": "5ZXIK5YJyY7u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìö Types of PEFT Methods\n",
        "Let‚Äôs look at some of the most common and impactful PEFT approaches:\n",
        "\n",
        "    Method                        | Core Idea\n",
        "    ------------------------------------------------------------------------------------\n",
        "    Adapter Tuning                | Add small bottleneck layers between transformer layers\n",
        "    LoRA (Low-Rank Adaptation)    | Inject low-rank matrices into weight updates\n",
        "    Prefix Tuning                 | Add learnable tokens at the start of each input\n",
        "    Prompt Tuning                 | Add learnable prompts instead of modifying the model\n",
        "    BitFit                        | Only fine-tune bias terms\n",
        "    IA¬≥ / HyperLoRA               | Modify only input-dependent scaling terms"
      ],
      "metadata": {
        "id": "XFHEph5byxAP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üßæ TL;DR of PEFT\n",
        "\n",
        "- Motivation: Avoid retraining massive models.\n",
        "\n",
        "- Strategy: Freeze the main model ‚Üí Add small trainable modules.\n",
        "\n",
        "- Result: Huge savings in time, compute, and storage ‚Äî without sacrificing much performance.\n",
        "___"
      ],
      "metadata": {
        "id": "KixOOCo2zh7J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîπ 3. LoRA ‚Äì Low-Rank Adaptation"
      ],
      "metadata": {
        "id": "ZBgXafke0E5g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† What Problem Does LoRA Solve?\n",
        "\n",
        "Let‚Äôs recall:\n",
        "\n",
        "In transformers, Linear layers (like Wq, Wk, Wv, Wo) are the heaviest components (millions of parameters).\n",
        "In standard fine-tuning, we update all of them.\n",
        "\n",
        "üí° LoRA‚Äôs idea:\n",
        "\n",
        "Don't update the full weight matrix. Instead, inject a low-rank decomposition to simulate the change in weights ‚Äî saving parameters, compute, and memory."
      ],
      "metadata": {
        "id": "u2W1aedLDHCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üßÆ Step-by-Step: LoRA Math Intuition\n",
        "Let‚Äôs break it down:\n",
        "\n",
        "üß± 1. Standard Linear Layer\n",
        "A transformer layer has a linear transformation:\n",
        "\n",
        "$$ y = Wx $$\n",
        "\n",
        "where:\n",
        "- $W ‚àà R^{d_{out}} \\times R^{d_{in}}$\n",
        "- $x ‚àà R^{d_{in}}$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "asqdtySbEqcx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß± 2. In Full Fine-Tuning:\n",
        "\n",
        "You update\n",
        "$ùëä$\n",
        "directly ‚Üí too many parameters."
      ],
      "metadata": {
        "id": "22FHIDpaJpTG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üí° 3. In LoRA:\n",
        "\n",
        "Keep $ùëä$ frozen, and add a low-rank adapter:  \n",
        "\n",
        "$$ùëä‚Ä≤ = ùëä + Œîùëä \\space\\space where \\space\\space Œîùëä = ùêµùê¥$$\n",
        "\n",
        "- $ùê¥ ‚àà ùëÖ^{ùëü√óùëë_{ùëñùëõ}}$\n",
        "\n",
        "- $ùêµ ‚àà ùëÖ^{ùëë_{ùëúùë¢ùë°}√óùëü}  $\n",
        "\n",
        "- $ùëü ‚â™ ùëë$  ‚Üí Low-rank matrices!  \n",
        "\n",
        "Then:  \n",
        "\n",
        "$$ùë¶ = (ùëä + ùêµùê¥)ùë• = ùëäùë• + ùêµùê¥ùë•$$\n",
        "\n",
        "üîë Only train $A$ and $B$, keep $W$ frozen.  "
      ],
      "metadata": {
        "id": "__t5rSSqJybe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¢ How Efficient Is This?\n",
        "\n",
        "If ùëü=8, and\n",
        "ùëä is 768√ó768 (over 590K parameters):\n",
        "\n",
        "- Fine-tuning W ‚Üí 590,000 parameters\n",
        "\n",
        "- LoRA (B and A) ‚Üí 8 √ó 768 + 768 √ó 8 = 12,288 parameters\n",
        "\n",
        "That's ~50√ó smaller!"
      ],
      "metadata": {
        "id": "NKCEDBPFLsCK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚öôÔ∏è LoRA Injection Points\n",
        "\n",
        "LoRA is typically applied to query and value projections in transformer blocks:\n",
        "\n",
        "- $W_q, W_v$ ‚Üí fine-tuned with LoRA\n",
        "\n",
        "- Everything else (e.g., FFN, other heads) ‚Üí frozen\n",
        "\n",
        "This leads to very little memory usage, and fast training."
      ],
      "metadata": {
        "id": "H1lW1Ip5MUBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Benefits of LoRA\n",
        "\n",
        "Benefit | Description\n",
        "--------|-----------------------------------------\n",
        "Efficiency | Tiny number of trainable parameters\n",
        "Speed | Fast training with fewer gradients\n",
        "Storage | Only store LoRA adapters (small files)\n",
        "Plug-n-Play | Easily load/unload adapters for tasks\n",
        "Modularity | Multiple tasks can reuse the same base model"
      ],
      "metadata": {
        "id": "B91gZW0tMxl2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ö†Ô∏è Any Trade-offs?\n",
        "\n",
        "- Slight loss in performance for some tasks if ùëü is too low.\n",
        "\n",
        "- Requires framework support (like ü§ó Transformers or PEFT lib)."
      ],
      "metadata": {
        "id": "o6rZ44S2Nyxo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîπ 4. LoRA vs Other PEFT Methods\n",
        "(üìä When to Use What?)"
      ],
      "metadata": {
        "id": "G4X0azy_fXBH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To choose the right PEFT technique, you need to understand:\n",
        "\n",
        "- How each one works\n",
        "\n",
        "- Their strengths and limitations\n",
        "\n",
        "- Their use cases\n",
        "\n",
        "Let‚Äôs break them down clearly."
      ],
      "metadata": {
        "id": "UY2KuxN6ffl9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† Summary of Common PEFT Techniques\n",
        "\n",
        "| PEFT Method        | Core Idea                                  | Param Count   | Key Use Cases             |\n",
        "| ------------------ | ------------------------------------------ | ------------- | ------------------------- |\n",
        "| **LoRA**           | Inject low-rank updates into linear layers | üî∏ Small      | NLP, CV, LLMs             |\n",
        "| **Adapter Tuning** | Add bottleneck layers between layers       | üî∏ Small‚ÄìMed  | Multilingual, NLP         |\n",
        "| **Prefix Tuning**  | Add learnable vectors at input level       | üîπ Very Small | Generation tasks          |\n",
        "| **Prompt Tuning**  | Train soft tokens prepended to input       | üîπ Very Small | Prompt-based tasks        |\n",
        "| **BitFit**         | Train only bias terms                      | üîπ Smallest   | Simple tasks, diagnostics |"
      ],
      "metadata": {
        "id": "sdotoB4jfmDj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîç Let‚Äôs Compare Them One by One:"
      ],
      "metadata": {
        "id": "JuuPUxr5frOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ LoRA\n",
        "\n",
        "**How it works:** Decomposes updates into low-rank matrices ‚Üí applied to linear layers.\n",
        "\n",
        "**Pros:**\n",
        "\n",
        "- Highly efficient for transformers\n",
        "\n",
        "- Doesn‚Äôt change architecture\n",
        "\n",
        "- Works well with attention-heavy models\n",
        "\n",
        "**Cons:**\n",
        "\n",
        "- Slight complexity in implementation\n",
        "\n",
        "Best for: LLMs, ViTs, when attention modules dominate."
      ],
      "metadata": {
        "id": "S_fsi61dft-e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Adapter Tuning\n",
        "\n",
        "**How it works:** Inserts small trainable MLP layers (bottlenecks) between frozen layers.\n",
        "\n",
        "**Pros:**\n",
        "\n",
        "- Strong performance in multilingual and multi-task learning\n",
        "\n",
        "- Good generalization\n",
        "\n",
        "**Cons:**\n",
        "\n",
        "- Adds more parameters than LoRA\n",
        "\n",
        "- Slightly larger memory footprint\n",
        "\n",
        "Best for: NLP, multilingual tasks, earlier transformer models (like BERT)."
      ],
      "metadata": {
        "id": "cCHeX7rpgBki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Prefix Tuning\n",
        "\n",
        "**How it works:** Adds trainable vectors (prefixes) to the input of each transformer block.\n",
        "\n",
        "**Pros:**\n",
        "\n",
        "- Ultra-lightweight\n",
        "\n",
        "- Keeps model architecture unchanged\n",
        "\n",
        "**Cons:**\n",
        "\n",
        "- Best for generation tasks only (e.g., summarization, translation)\n",
        "\n",
        "- Weaker for classification\n",
        "\n",
        "Best for: GPT-style autoregressive models."
      ],
      "metadata": {
        "id": "5Kz1u0m_gQxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Prompt Tuning\n",
        "\n",
        "**How it works:** Adds a set of soft (learnable) tokens to the input prompt.\n",
        "\n",
        "**Pros:**\n",
        "\n",
        "- Lightweight\n",
        "\n",
        "- Minimal parameter footprint\n",
        "\n",
        "**Cons:**\n",
        "\n",
        "- Needs good initialization\n",
        "\n",
        "- Can be task-specific\n",
        "\n",
        "Best for: Simple prompt-driven tasks, often in zero-/few-shot setups."
      ],
      "metadata": {
        "id": "-imW5Pv7gat4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ BitFit\n",
        "\n",
        "**How it works:** Only train bias terms in the model.\n",
        "\n",
        "**Pros:**\n",
        "\n",
        "- Dead simple\n",
        "\n",
        "- Tiny memory cost\n",
        "\n",
        "**Cons:**\n",
        "\n",
        "- Often underperforms on complex tasks\n",
        "\n",
        "Best for: Diagnostics, toy experiments."
      ],
      "metadata": {
        "id": "y_jqSjhIgkE9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Situation                                                    | Is LoRA a good fit? |\n",
        "| ------------------------------------------------------------ | ------------------- |\n",
        "| LLMs or ViT-based models? |                   ‚úÖ Yes                                                   |\n",
        "| Memory/Compute constrained? | ‚úÖ Yes                                                 |\n",
        "| Inference performance matters? | ‚úÖ Yes                                              |\n",
        "| Want task-specific adapters? | ‚úÖ Yes                                                |\n",
        "| Need extreme miniaturization? | ‚ùå Go with Prompt/Prefix Tuning                      |\n",
        "| Working with encoder-only models? | ‚úÖ LoRA or Adapters                              |\n"
      ],
      "metadata": {
        "id": "ozIxx-sLgrbX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üßæ TL;DR Summary\n",
        "\n",
        "| If You Want...                      | Use This PEFT                     |\n",
        "| ----------------------------------- | --------------------------------- |\n",
        "| Balance of efficiency + performance | ‚úÖ **LoRA**                        |\n",
        "| Simple tuning + very low memory     | ‚úÖ **BitFit** or **Prompt Tuning** |\n",
        "| Strong multilingual performance     | ‚úÖ **Adapters**                    |\n",
        "| Fast inference + low storage        | ‚úÖ **LoRA**                        |\n",
        "| Tiny models for mobile/edge         | ‚úÖ **Prompt Tuning**               |\n"
      ],
      "metadata": {
        "id": "w9nFa74WhH5z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† Mastery Insight\n",
        "\n",
        "In modern LLM workflows, LoRA is the go-to method due to its:\n",
        "\n",
        "- High efficiency\n",
        "\n",
        "- Reusability\n",
        "\n",
        "- Ease of plugging into HuggingFace and PEFT pipelines"
      ],
      "metadata": {
        "id": "ld8knFN2hMuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîπ 5. Advanced PEFT: QLoRA, AdaLoRA & Transformers Integration\n",
        "These techniques help push the limits of LoRA even further ‚Äî either by reducing memory (QLoRA), making the model adapt intelligently (AdaLoRA), or integrating easily in production workflows."
      ],
      "metadata": {
        "id": "8dnvSzvTh6He"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† 5.1 QLoRA ‚Äì Quantized LoRA\n",
        "\n",
        "‚ùì What is QLoRA?\n",
        "\n",
        "QLoRA = Quantized Model + LoRA adapters\n",
        "\n",
        "It allows you to fine-tune a massive model (like 65B) on a single GPU with:\n",
        "\n",
        "- 4-bit quantization of base model\n",
        "\n",
        "- LoRA adapters on top\n",
        "\n",
        "‚úÖ This enables low-memory fine-tuning without sacrificing quality."
      ],
      "metadata": {
        "id": "V2TQFZUviV66"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚öôÔ∏è Key Ingredients of QLoRA\n",
        "\n",
        "| Component            | Role                                    |\n",
        "| -------------------- | --------------------------------------- |\n",
        "| 4-bit Quantization   | Compress base model weights (less VRAM) |\n",
        "| LoRA Adapters        | Learn task-specific deltas              |\n",
        "| Double Quantization  | Further compress optimizer state        |\n",
        "| Paginated Optimizers | Efficient memory paging during training |\n"
      ],
      "metadata": {
        "id": "QFp7eTgfj3xD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¨ How It Works:\n",
        "\n",
        "1. Load a pretrained model in 4-bit quantized format.\n",
        "\n",
        "2. Freeze all base weights.\n",
        "\n",
        "3. Inject LoRA adapters.\n",
        "\n",
        "4. Train only LoRA (as usual).\n",
        "\n",
        "5. Save just the adapters.\n",
        "\n",
        "‚ö° The base model is compressed AND untouched ‚Üí memory-efficient + reusable!"
      ],
      "metadata": {
        "id": "eELsLKX5j8s5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† Why Is QLoRA Important?\n",
        "\n",
        "- You can fine-tune models like LLaMA-7B or LLaMA-65B on 1 consumer GPU (24GB).\n",
        "\n",
        "- Dramatic memory savings (~70%+)\n",
        "\n",
        "- Achieves state-of-the-art performance with very few parameters trained"
      ],
      "metadata": {
        "id": "Hm7tQCnHkNUv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ 5.2 AdaLoRA ‚Äì Adaptive LoRA\n",
        "\n",
        "‚ùì What is AdaLoRA?\n",
        "\n",
        "Instead of keeping the rank r constant, AdaLoRA dynamically adjusts it during training.\n",
        "\n",
        "üí° Some layers benefit from higher capacity; others do not. AdaLoRA learns which layers matter more and allocates ranks intelligently."
      ],
      "metadata": {
        "id": "AxkAgeTTkSb2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† How It Works\n",
        "\n",
        "1. Start with max rank for all LoRA layers.\n",
        "\n",
        "2. Use a rank allocator that prunes or adjusts ranks over time.\n",
        "\n",
        "3. Converge to a compressed set of LoRA adapters.\n",
        "\n",
        "üîÑ The model learns where to focus its capacity ‚Äî leads to better performance with the same budget."
      ],
      "metadata": {
        "id": "c8J7CNxSkZlX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî¨ Benefits of AdaLoRA\n",
        "\n",
        "| Benefit            | Description                                 |\n",
        "| ------------------ | ------------------------------------------- |\n",
        "| Smarter LoRA       | Learns to use rank more effectively         |\n",
        "| Higher performance | Better than fixed-rank LoRA in many tasks   |\n",
        "| Compression-aware  | Automatically compresses unimportant layers |\n"
      ],
      "metadata": {
        "id": "r9v9TVz1kdr2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ 5.3 LoRA in HuggingFace & PEFT Workflows\n",
        "\n",
        "‚úÖ HuggingFace PEFT Integration\n",
        "\n",
        "You can use LoRA in ü§ó PEFT with just a few lines:\n",
        "\n",
        "```\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=8, lora_alpha=16,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.1,\n",
        "    task_type=\"SEQ_CLS\"  # or CAUSAL_LM, TOKEN_CLS, etc.\n",
        ")\n",
        "\n",
        "model = get_peft_model(base_model, config)\n",
        "```\n",
        "The library:\n",
        "\n",
        "- Automatically freezes base model\n",
        "\n",
        "- Adds LoRA\n",
        "\n",
        "- Makes saving/loading adapters easy"
      ],
      "metadata": {
        "id": "dWPYAt0lkgUI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† When to Use Each?\n",
        "\n",
        "| Scenario                            | Use This                              |\n",
        "| ----------------------------------- | ------------------------------------- |\n",
        "| You have a small GPU (<= 24GB)      | ‚úÖ QLoRA                               |\n",
        "| You want best possible accuracy     | ‚úÖ AdaLoRA                             |\n",
        "| You want a production-friendly flow | ‚úÖ PEFT + LoRA                         |\n",
        "| You want multi-task support         | ‚úÖ LoRA or Adapters                    |\n",
        "| You need edge/mobile deployment     | ‚ùå Avoid full LoRA (use Prompt Tuning) |\n"
      ],
      "metadata": {
        "id": "3DtT-JzWlOO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ Milestone Unlocked: Advanced LoRA\n",
        "\n",
        "You now understand:\n",
        "\n",
        "- üî∑ QLoRA: Fine-tune huge models with small VRAM\n",
        "\n",
        "- üî∑ AdaLoRA: Learn dynamic ranks\n",
        "\n",
        "- üî∑ How to use LoRA in real-world pipelines"
      ],
      "metadata": {
        "id": "1X_LuTURlW9h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîπ 6. Practical Project: Fine-Tune a Model with LoRA (End-to-End)\n",
        "We'll start with a text classification task ‚Äî simple but powerful ‚Äî and use LoRA to fine-tune a transformer on it."
      ],
      "metadata": {
        "id": "9EzuAJv7ntKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üóÇÔ∏è Project: Sentiment Classification using LoRA\n",
        "\n",
        "| Task | Sentiment Analysis (binary: pos/neg) |\n",
        "|---------------------|--------------------------|\n",
        "| Dataset | IMDB / Yelp / SST-2 (small but real) |\n",
        "| Model | bert-base-uncased |\n",
        "| Library Stack | HuggingFace Transformers + Datasets + PEFT |\n",
        "| PEFT Method | LoRA |\n",
        "| Training Setup | 1 GPU (or CPU if needed, slower) |"
      ],
      "metadata": {
        "id": "uuepAvQgn3Iq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOwhY9dHtxAQ"
      },
      "outputs": [],
      "source": [
        "# üîß Step 1: Install Required Libraries\n",
        "# If you're working in Colab or your local machine, install:\n",
        "\n",
        "!pip install transformers datasets peft accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üß© Step 2: Load Dataset\n",
        "# Let‚Äôs use the HuggingFace datasets library:\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load SST-2 (Stanford Sentiment Treebank)\n",
        "dataset = load_dataset(\"glue\", \"sst2\")\n",
        "\n",
        "# SST-2 is binary: label = 1 (positive), 0 (negative)"
      ],
      "metadata": {
        "id": "Fz96w9PVomJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üß† Step 3: Tokenize Data\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize(example):\n",
        "    return tokenizer(example[\"sentence\"], truncation=True, padding=\"max_length\", max_length=128)\n",
        "\n",
        "encoded = dataset.map(tokenize, batched=True)\n",
        "encoded = encoded.rename_column(\"label\", \"labels\")\n",
        "encoded.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
      ],
      "metadata": {
        "id": "Zul79DStZvas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üèóÔ∏è Step 4: Load Base Model & Apply LoRA\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "# Define LoRA config\n",
        "config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"query\", \"value\"],  # for BERT\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_CLS\n",
        ")\n",
        "\n",
        "# Inject LoRA into model\n",
        "model = get_peft_model(model, config)\n",
        "\n",
        "# Print total vs trainable params\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "qnp7DDOOZ_lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üèãÔ∏è Step 5: Train the LoRA Model\n",
        "# We‚Äôll use ü§ó Trainer for simplicity:\n",
        "\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./lora-sst2\",\n",
        "    learning_rate=2e-4,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=3,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=encoded[\"train\"],\n",
        "    eval_dataset=encoded[\"validation\"]\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "t_ArIrjBaJZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üíæ Step 6: Save the LoRA Adapter (Not Full Model)\n",
        "\n",
        "# Only LoRA adapter weights\n",
        "model.save_pretrained(\"lora_adapter_sst2\")"
      ],
      "metadata": {
        "id": "k08Vfr6taO-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Later, you can plug this adapter into the base BERT model easily!"
      ],
      "metadata": {
        "id": "DYq4u_uvaXEH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚úÖ What You‚Äôve Learned from This Practical:\n",
        "\n",
        "| Concept             | You‚Äôve Done It! ‚úÖ |\n",
        "| ------------------- | ----------------- |\n",
        "| Load a dataset      | ‚úÖ                 |\n",
        "| Tokenize it         | ‚úÖ                 |\n",
        "| Load base model     | ‚úÖ                 |\n",
        "| Add LoRA adapters   | ‚úÖ                 |\n",
        "| Train only adapters | ‚úÖ                 |\n",
        "| Save LoRA only      | ‚úÖ                 |\n"
      ],
      "metadata": {
        "id": "BOJi_BlVacL9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0t06-7BAaYWy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}